# LLM Generator - Intelligent Environment Code Generator

An AI-powered code generation system that automatically creates complete, runnable OpenEnv-compatible environments using Large Language Models.

## Overview

The LLM Generator is a multi-agent system that generates full-stack applications (backend API + frontend UI + OpenEnv adapter) from natural language descriptions. Unlike simple template-based generators, it uses an iterative approach similar to how a human developer works:

1. **Think** - Understand the requirements
2. **Plan** - Decide what files to generate
3. **Generate** - Create code file by file
4. **Reflect** - Check for errors and issues
5. **Fix** - Automatically repair problems
6. **Test** - Run the code to verify it works

## Architecture

```
llm_generator/
â”œâ”€â”€ main.py                 # CLI entry point
â”œâ”€â”€ __init__.py
â”œâ”€â”€ context.py              # Generation context management
â”œâ”€â”€ events.py               # Real-time event streaming
â”œâ”€â”€ checkpoint.py           # Progress persistence for resume
â”œâ”€â”€ snippets/               # Code templates library
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ backend_snippets.py
â”‚   â”œâ”€â”€ frontend_snippets.py
â”‚   â””â”€â”€ openenv_snippets.py
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py     # Main orchestrator (coordinates phases)
â”‚   â””â”€â”€ code_agent.py       # Code generation agent
â””â”€â”€ tools/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ file_tools.py       # File system operations
    â”œâ”€â”€ code_tools.py       # Code manipulation (grep, search_replace, lint)
    â””â”€â”€ runtime_tools.py    # Server management, API testing
```

## Key Components

### 1. GeneratorOrchestrator (`orchestrator.py`)

The main coordinator that manages the generation process across multiple phases:

- **Design Phase**: Generate `env_spec.json` with environment specification
- **Backend Phase**: Generate FastAPI backend with authentication
- **Frontend Phase**: Generate React/TypeScript frontend
- **OpenEnv Phase**: Generate OpenEnv adapter for RL integration

Each phase runs through **3 iterations**:
1. **GENERATE**: Create all planned files
2. **VERIFY & FIX**: Run tests, identify issues, apply fixes
3. **FINAL CHECK**: Ensure everything works

### 2. CodeGeneratorAgent (`code_agent.py`)

The intelligent agent that generates individual files with:

- **Dynamic Planning**: LLM decides which files to generate (not hardcoded)
- **Context Gathering**: Uses `grep` and `read_file` to understand existing code
- **Per-File Intelligence**: Thinks before generating each file
- **Reflection**: Checks generated code for issues
- **Self-Fixing**: Automatically repairs detected problems

### 3. Tools

The agent has access to various tools:

#### File Tools
- `read_file(path, start_line?, end_line?)` - Read files with optional line range
- `write_file(path, content)` - Create/overwrite files
- `list_dir(path)` - List directory contents
- `file_exists(path)` - Check if file exists
- `list_generated(phase?)` - List all generated files with summaries

#### Code Tools
- `grep(pattern, path)` - Search for patterns across files
- `search_replace(path, old, new)` - Replace text in files
- `edit_lines(path, start, end, content)` - Replace specific line range
- `insert_lines(path, after_line, content)` - Insert lines at position
- `edit_function(path, name, new_code)` - Replace entire function/class
- `lint(path)` - Check code for errors
- `syntax_check(code, language)` - Verify syntax before writing

#### Runtime Tools
- `install_dependencies(project_type, cwd)` - Install pip/npm packages
- `start_server(name, command, cwd, port)` - Start backend/frontend server
- `stop_server(name)` - Stop a running server
- `test_api(method, url, json_data?)` - Test API endpoints
- `get_server_logs(name)` - Get server output for debugging
- `quick_test(backend_dir)` - Automated backend test cycle

## Generation Flow

### Phase Execution (3 Iterations)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PHASE: backend                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ITERATION 1: GENERATE                                       â”‚
â”‚   â”œâ”€â”€ Think: Analyze phase requirements                     â”‚
â”‚   â”œâ”€â”€ Plan: LLM decides files to generate                   â”‚
â”‚   â””â”€â”€ Generate: Create each file with per-file intelligence â”‚
â”‚       â”œâ”€â”€ think_before_file() - What context needed?        â”‚
â”‚       â”œâ”€â”€ gather_context_dynamically() - Read/grep files    â”‚
â”‚       â”œâ”€â”€ generate_file() - Create the code                 â”‚
â”‚       â””â”€â”€ reflect_on_file() - Check for issues              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ITERATION 2: VERIFY & FIX                                   â”‚
â”‚   â”œâ”€â”€ Check for missing planned files                       â”‚
â”‚   â”œâ”€â”€ Run runtime tests (start server, test API)            â”‚
â”‚   â”œâ”€â”€ Collect all issues                                    â”‚
â”‚   â”œâ”€â”€ Call fix_issues() to repair                           â”‚
â”‚   â””â”€â”€ Re-test after fixes                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ITERATION 3: FINAL CHECK                                    â”‚
â”‚   â”œâ”€â”€ Handle any remaining issues from iteration 2          â”‚
â”‚   â”œâ”€â”€ Run final tests                                       â”‚
â”‚   â””â”€â”€ Mark phase complete (success/failure)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Per-File Generation Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Generating: calendar_api/main.py            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. think_before_file()                                   â”‚
â”‚    â””â”€â”€ LLM decides: "I need to read database.py and     â”‚
â”‚        schemas.py, grep for 'APIRouter' patterns"        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. gather_context_dynamically()                          â”‚
â”‚    â”œâ”€â”€ read_file("calendar_api/database.py")            â”‚
â”‚    â”œâ”€â”€ read_file("calendar_api/schemas.py")             â”‚
â”‚    â””â”€â”€ grep("APIRouter", ".")                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. generate_file()                                       â”‚
â”‚    â”œâ”€â”€ Build prompt with context                         â”‚
â”‚    â”œâ”€â”€ Call LLM to generate code                         â”‚
â”‚    â”œâ”€â”€ Strip line numbers if present                     â”‚
â”‚    â”œâ”€â”€ Fix JSON formatting if needed                     â”‚
â”‚    â””â”€â”€ Write file                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. reflect_on_file()                                     â”‚
â”‚    â”œâ”€â”€ Run syntax_check()                               â”‚
â”‚    â”œâ”€â”€ Run lint()                                       â”‚
â”‚    â”œâ”€â”€ LLM analyzes code quality                        â”‚
â”‚    â””â”€â”€ Return issues list                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 5. fix_issues() (if issues found)                        â”‚
â”‚    â”œâ”€â”€ Parse issue type (IMPORT, SYNTAX, MISSING, etc.) â”‚
â”‚    â”œâ”€â”€ Apply appropriate fix strategy                    â”‚
â”‚    â””â”€â”€ Re-validate after fix                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Issue Detection & Auto-Fixing

The system can detect and fix various issues:

### Issue Types & Fix Strategies

| Issue Type | Detection | Fix Strategy |
|------------|-----------|--------------|
| `IMPORT ERROR: ModuleNotFoundError` | Server fails to start | Convert absolute imports to relative imports |
| `MISSING FILE` | Import references non-existent file | Generate the missing file |
| `SYNTAX ERROR` | syntax_check fails | Regenerate file or apply targeted fix |
| `TRUNCATED` | Code appears incomplete | Continue generation with LLM |
| `JSON FORMATTING` | Single-line JSON | Reformat with proper indentation |
| `INCOMPLETE` | Contains TODO/FIXME markers | Regenerate with complete implementation |

### Example: Import Error Fix

```python
# Detected issue:
"IMPORT ERROR: ModuleNotFoundError: No module named 'calendar_api'. 
This usually means the imports need to be changed to relative imports."

# Fix applied:
# Before: from calendar_api.database import init_db
# After:  from .database import init_db
```

## Runtime Testing

The system includes automated testing capabilities:

1. **Dependency Installation**: `pip install -r requirements.txt`
2. **Server Startup**: `uvicorn main:app --host 0.0.0.0 --port 8008`
3. **API Testing**: 
   - Health check: `GET /health`
   - Registration: `POST /auth/register`
   - Login: `POST /auth/token`
4. **Error Analysis**: Parse server logs for specific error types
5. **Automatic Cleanup**: Stop servers after testing

## Usage

### Basic Usage

```bash
cd Agents/env_generator
python -m llm_generator.main \
    --name calendar \
    --description "A calendar app with events and authentication" \
    --verbose
```

### With Runtime Testing

```bash
python -m llm_generator.main \
    --name calendar \
    --description "A calendar app" \
    --test \
    --verbose
```

### Resume from Checkpoint

```bash
python -m llm_generator.main \
    --name calendar \
    --description "A calendar app" \
    --resume \
    --verbose
```

### CLI Arguments

| Argument | Description |
|----------|-------------|
| `--name` | Environment name (e.g., "calendar") |
| `--description` | Natural language description |
| `--domain` | Domain type: "web_gui", "cli", "game", etc. |
| `--output` | Output directory (default: "generated") |
| `--test` | Enable runtime testing |
| `--resume` | Resume from checkpoint |
| `--verbose` | Enable detailed logging |
| `--model` | LLM model (default: "gpt-5.1") |

## Output Structure

Generated environment structure:

```
generated/calendar/
â”œâ”€â”€ env_spec.json              # Environment specification
â”œâ”€â”€ calendar_api/              # FastAPI backend
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                # FastAPI app entry point
â”‚   â”œâ”€â”€ database.py            # Database configuration
â”‚   â”œâ”€â”€ models.py              # SQLAlchemy models
â”‚   â”œâ”€â”€ schemas.py             # Pydantic schemas
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â””â”€â”€ routers/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ auth.py            # Authentication endpoints
â”œâ”€â”€ calendar_ui/               # React frontend
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ tsconfig.node.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.tsx
â”‚       â”œâ”€â”€ App.tsx
â”‚       â”œâ”€â”€ index.css
â”‚       â”œâ”€â”€ contexts/
â”‚       â”œâ”€â”€ pages/
â”‚       â””â”€â”€ services/
â””â”€â”€ openenv_adapter/           # OpenEnv integration
    â”œâ”€â”€ models.py
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ server/
        â”œâ”€â”€ environment.py
        â””â”€â”€ main.py
```

## Real-time Logging

The system provides two log files:

1. **`{name}_realtime.log`**: Human-readable event stream
   ```
   [21:22:09] ğŸ¤” THINK: ITERATION 1/3
   [21:22:09] ğŸ“‹ PLAN: 8 files for phase
   [21:22:30] START: calendar_api/main.py
   [21:22:45] ğŸ”§ TOOL: grep pattern='APIRouter'
   [21:22:46] DONE: calendar_api/main.py (45 lines, good)
   ```

2. **`{name}_generation.log`**: JSON event log for programmatic analysis

## Memory System

The generator uses a shared memory system across phases:

- **Short-term**: Recent context (FIFO buffer)
- **Long-term**: Important patterns and fixes
- **Working**: Current task context

This enables:
- Learning from fixes applied in earlier phases
- Maintaining consistency across generated files
- Recalling relevant patterns for similar files

## Checkpointing

Progress is automatically saved to `.checkpoint.json`:

```json
{
  "name": "calendar",
  "current_phase": "backend",
  "phases": {
    "design": {"status": "complete", "files": ["env_spec.json"]},
    "backend": {"status": "in_progress", "files": ["main.py", "database.py"]}
  },
  "files": {
    "calendar_api/main.py": {
      "status": "complete",
      "content_hash": "abc123...",
      "phase": "backend"
    }
  }
}
```

## Known Limitations

1. **Line Numbers in Output**: LLMs sometimes output code with embedded line numbers. The system now strips these automatically.

2. **Import Resolution**: When running from subdirectories, absolute imports may fail. The system detects this and converts to relative imports.

3. **Server Port Conflicts**: Orphan processes from previous runs can cause port conflicts. The system now checks and cleans up before testing.

4. **tsconfig.node.json**: Special handling added for TypeScript configuration files to ensure valid output.

## Environment Variables

| Variable | Description |
|----------|-------------|
| `OPENAI_API_KEY` | OpenAI API key for GPT models |

## Dependencies

- Python 3.9+
- OpenAI API (GPT-4, GPT-4o, or GPT-5.1)
- FastAPI, Uvicorn (for backend)
- Node.js, npm (for frontend)

## Contributing

The system is designed to be extensible:

1. **Add new tools**: Create in `tools/` and register in `code_agent.py`
2. **Add code snippets**: Add to `snippets/` for common patterns
3. **Customize phases**: Modify `_get_phase_spec()` in `orchestrator.py`

## License

[Your License Here]
